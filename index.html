<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head>
  <meta charset="utf-8">

  <!-- Always force latest IE rendering engine or request Chrome Frame -->
  <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
  <meta http-equiv="cleartype" content="on">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Use title if it's in the page YAML frontmatter -->
  <title>Image Segmentation for Tekkotsu</title>
  <meta name="description" content="New image segmentation method for Tekkotsu.">
  <meta name="author" content="Cary Yang, Jeff Chen">

  <link href="stylesheets/global-6521834d.css" media="all" rel="stylesheet" type="text/css" />
  <link href="stylesheets/layout-72c7f904.css" media="all and (min-width: 33.236em)" rel="stylesheet" type="text/css" />
  <!-- 30em + (1.618em * 2) = 33.236em / Eliminates potential of horizontal scrolling in most cases -->

  <!--[if (lt IE 9) & (!IEMobile)]>
  <link href="stylesheets/layout-72c7f904.css" media="all" rel="stylesheet" type="text/css" />
  <![endif]-->

  <link href="stylesheets/all-d6498be1.css" media="screen" rel="stylesheet" type="text/css" />
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open Sans:300,400,700,300italic,400italic,700italic" />
<!--[if IE]>
<link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open Sans:300" />
<link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open Sans:400" />
<link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open Sans:700" />
<link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open Sans:300italic" />
<link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open Sans:400italic" />
<link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open Sans:700italic" />
<![endif]-->

</head>

<body class="index">
  <div id="container" class="cf">
    <div id="main" role="main" class="cf">
      <p><header></p>

<h1>Image Segmentation <span>Tekkotsu</span></h1>

<p></header></p>

<h3>Jeff Chen (jchen4), Cary Yang (caryy)</h3>

<p>When examining the pictures, we noticed that both the regular (rgb) images and the depth images had very clearly delineated blocks. The first thing that we tried took only the rgb image into account &ndash; we simply thresholded the image with an arbitrary constant (0.65) using <code>img2bw</code>, then found the largest blob using <code>regionprops</code>. The output of <code>regionprops</code> included all necessary information, including the blob&rsquo;s centroid, orientation, and axis lengths. This worked well for the pictures with only the top face of the block showing. However, when more than one face of the block was showing, the calculated centroid would be offset, since the threshold would capture both faces of the block.</p>

<p><aside class="figure">
    <h4 class="figure-title">Figure 1: Output on <code>rgba1.png</code></h4>
    <img src="images/asst2fig1.png" />
</aside></p>

<p>Next, we tried doing the same thing, but on the depth image. However, while the depth image was able to clearly distinguish between the block faces, the pictures were not taken from directly above the block, so some parts of the block were relatively far away. In fact, with a basic threshold, to capture all of the block, other pieces of the image would also be captured, creating other blobs that were bigger than the block blobs.</p>

<p>The solution we found was to combine the two strategies. First, we found the largest, but potentially inaccurate, blob from the rgb image. Next, we found all of the blobs from the depth image with a relatively unrestrictive threshold, to ensure that the entire top face of the blob would be captured. Then, we iterated through the depth blobs&#39; centroids, finding the depth blob that had the closest centroid to the rgb blob. We then used the found depth blob to find the centroid, orientation, and axis length data. This method proved remarkably accurate &ndash; though the images did not have any provided scale, the centroids appear to be within 10 pixels, and the orientation is almost perfect.</p>

<p><aside class="figure">
    <h4 class="figure-title">Figure 2: Output on <code>rgba8.png</code></h4>
    <img src="images/asst2fig8.png" />
</aside></p>

<p>Our function <code>get_blob_data</code> will display a window with the calculated centroid (green dot), and major and minor axes of the circumscribed ellipse (blue and red lines, respectively) on top of the rgb image. In addition, the image is overlayed with a translucent version of the segmented depth image. The function takes in as input the image number and will output a vector of <code>[centroid, orientation]</code>.</p>

<div id="download-btn-container">
  <a href="asst2code.zip" class="btn blue" role="button">
    <i class="icon ion-code-download"></i>
    Download Our Code
  </a>
</div>

    </div>
  </div>
  
  <script src="javascripts/all-2229cc6f.js" type="text/javascript"></script>
</body>
</html>